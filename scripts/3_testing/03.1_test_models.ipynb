{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test individual model performance and ensemble model performance\n",
    "# Last updated: 5/18/2024 by NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b31d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Load objects\n",
    "\n",
    "rm(list=ls())\n",
    "options(warn=-1)\n",
    "\n",
    "# Libraries\n",
    "suppressPackageStartupMessages({\n",
    "    \n",
    "    library(lme4)\n",
    "    library(tidymodels)\n",
    "    library(dplyr)\n",
    "    library(xgboost)\n",
    "    library(glmnet)\n",
    "    library(ranger)\n",
    "    library(pROC)\n",
    "    library(yardstick)\n",
    "    library(Metrics)\n",
    "    \n",
    "})\n",
    "\n",
    "# Set wd\n",
    "setwd('~/Desktop/GitHub/CES_prediction')\n",
    "\n",
    "# Data\n",
    "load('temp/poll_train.rda')\n",
    "load('temp/poll_test.rda')\n",
    "\n",
    "# Functions\n",
    "source('scripts/0_functions/00_create_directory.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9b922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create recipes to pre-process data for models \n",
    "\n",
    "dv <- 'climate_change_worry'\n",
    "recipe_formula <- as.formula(paste0(dv, ' ~ .'))\n",
    "\n",
    "# 1.1. XGBoost recipe ---------------------------------------------------------\n",
    "\n",
    "xgb_recipe_train <- poll_train %>%\n",
    "  recipe(recipe_formula) %>% \n",
    "  step_dummy(all_nominal_predictors()) %>% # dummy encode \n",
    "  step_select(-evangelical_Other) %>% # remove zero-variance\n",
    "  step_normalize(all_numeric_predictors()) # normalize \n",
    "\n",
    "# 1.2. Random forest recipe ---------------------------------------------------\n",
    "\n",
    "rf_recipe_train <- poll_train %>%\n",
    "  recipe(recipe_formula) %>% \n",
    "  step_normalize(all_numeric_predictors())  \n",
    "\n",
    "# 1.3. Elastic net recipe -----------------------------------------------------\n",
    "\n",
    "enet_recipe_train <- poll_train %>%\n",
    "  recipe(recipe_formula) %>% \n",
    "  step_dummy(all_nominal_predictors()) %>% \n",
    "  step_select(-evangelical_Other) %>% # remove zero-variance\n",
    "  step_normalize(all_numeric())  \n",
    "\n",
    "# 1.4. PCA recipe -------------------------------------------------------------\n",
    "\n",
    "pca_recipe_train <- poll_train %>%\n",
    "  recipe(recipe_formula) %>% \n",
    "  step_normalize(all_numeric_predictors()) %>%  \n",
    "  step_pca(all_numeric_predictors(), num_comp = 4) # num_comp determined from tuning\n",
    "\n",
    "# 1.5. Best subsets recipe ------------------------------------------------\n",
    "\n",
    "bestsub_recipe_train <- poll_train %>%\n",
    "  recipe(recipe_formula) %>% \n",
    "  step_normalize(all_numeric_predictors()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca62c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pre-process data for models \n",
    "\n",
    "# 2.1. XGBoost ----------------------------------------------------------------\n",
    "\n",
    "xgb_train <- xgb_recipe_train %>%\n",
    "  prep() %>%\n",
    "  juice()\n",
    "\n",
    "xgb_test <- xgb_recipe_train %>%\n",
    "  prep() %>%\n",
    "  bake(poll_test)\n",
    "\n",
    "# 2.2. Random forest ----------------------------------------------------------\n",
    "\n",
    "rf_train <- rf_recipe_train %>%\n",
    "  prep() %>%\n",
    "  juice()\n",
    "\n",
    "rf_test <- rf_recipe_train %>%\n",
    "  prep() %>%\n",
    "  bake(poll_test)\n",
    "\n",
    "# 2.3. Elastic net ------------------------------------------------------------\n",
    "\n",
    "enet_train <- enet_recipe_train %>%\n",
    "  prep() %>%\n",
    "  juice()\n",
    "\n",
    "enet_test <- enet_recipe_train %>%\n",
    "  prep() %>%\n",
    "  bake(poll_test)\n",
    "\n",
    "# 2.4. PCA --------------------------------------------------------------------\n",
    "\n",
    "pca_train <- pca_recipe_train %>%\n",
    "  prep() %>%\n",
    "  juice()\n",
    "\n",
    "pca_test <- pca_recipe_train %>%\n",
    "  prep() %>%\n",
    "  bake(poll_test)\n",
    "\n",
    "# 2.5. Best subsets -----------------------------------------------------------\n",
    "\n",
    "bestsub_train <- bestsub_recipe_train %>%\n",
    "  prep() %>%\n",
    "  juice()\n",
    "\n",
    "bestsub_test <- bestsub_recipe_train %>%\n",
    "  prep() %>%\n",
    "  bake(poll_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34aa07e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in auc(.): argument \"predicted\" is missing, with no default\n",
     "output_type": "error",
     "traceback": [
      "Error in auc(.): argument \"predicted\" is missing, with no default\nTraceback:\n",
      "1. roc(xgb_test_pred_all[[\"truth\"]], xgb_test_pred_all[[\"pred_prob\"]]) %>% \n .     auc()",
      "2. auc(.)"
     ]
    }
   ],
   "source": [
    "# 3. Train tuned model, run on test data, track predictions and performance\n",
    "\n",
    "# Store model performance on test set\n",
    "aucs <- list()\n",
    "log_losses <- list()\n",
    "\n",
    "# 3.1. XGBoost ----------------------------------------------------------------\n",
    "\n",
    "# Load tuned hparams\n",
    "load('temp/tuning/xgb_tuning.rda') \n",
    "\n",
    "# Define model with optimal hparams\n",
    "xgb_model <- boost_tree(\n",
    "  trees = xgb_tune_best[['trees']], \n",
    "  min_n = xgb_tune_best[['min_n']],\n",
    "  tree_depth = xgb_tune_best[['tree_depth']], \n",
    "  learn_rate = xgb_tune_best[['learn_rate']], \n",
    "  sample_size = xgb_tune_best[['sample_size']], \n",
    "  stop_iter = xgb_tune_best[['stop_iter']]) %>% \n",
    "  set_mode('classification') %>% \n",
    "  set_engine('xgboost')\n",
    "\n",
    "# Define model formula \n",
    "dv <- 'climate_change_worry' \n",
    "xgb_formula <- as.formula(paste0(dv, \" ~ .\"))\n",
    "\n",
    "# Fit model to training data\n",
    "xgb_fit <- xgb_model %>% \n",
    "  fit(xgb_formula, data=xgb_train)\n",
    "\n",
    "# Create test assessment object \n",
    "xgb_test_pred_class <- predict(xgb_fit, new_data=xgb_test)\n",
    "xgb_test_pred_prob <- predict(xgb_fit, new_data=xgb_test, type='prob') %>% dplyr::select(.pred_1)\n",
    "xgb_test_pred_all <- cbind(xgb_test_pred_class, xgb_test_pred_prob, xgb_test[['climate_change_worry']]) \n",
    "names(xgb_test_pred_all) <- c('pred_class', 'pred_prob', 'truth')\n",
    "\n",
    "# Assess model performance on test set \n",
    "(xgb_auc <- roc(xgb_test_pred_all[['truth']], xgb_test_pred_all[['pred_prob']]) %>% pROC::auc())\n",
    "(xgb_logloss <- logLoss(as.numeric(xgb_test_pred_all[['truth']]), xgb_test_pred_all[['pred_prob']]))\n",
    "\n",
    "\n",
    "# Add results to list \n",
    "aucs[['xgboost']] <- xgb_auc\n",
    "log_losses[['xgboost']] <- xgb_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cb0a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.805653186819106"
      ],
      "text/latex": [
       "0.805653186819106"
      ],
      "text/markdown": [
       "0.805653186819106"
      ],
      "text/plain": [
       "Area under the curve: 0.8057"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.399761758650486"
      ],
      "text/latex": [
       "-0.399761758650486"
      ],
      "text/markdown": [
       "-0.399761758650486"
      ],
      "text/plain": [
       "[1] -0.3997618"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.2. Random forest \n",
    "\n",
    "load('temp/tuning/rf_tuning.rda')\n",
    "\n",
    "rf_model <- rand_forest(\n",
    "  trees = rf_tune_best[['trees']], \n",
    "  min_n = rf_tune_best[['min_n']],\n",
    "  mtry = rf_tune_best[['mtry']]) %>% \n",
    "  set_mode('classification') %>% \n",
    "  set_engine('ranger')\n",
    "\n",
    "dv <- 'climate_change_worry' \n",
    "rf_formula <- as.formula(paste0(dv, ' ~ .'))\n",
    "\n",
    "rf_fit <- rf_model %>% \n",
    "  fit(rf_formula, data = rf_train)\n",
    "\n",
    "# Create test assessment object \n",
    "rf_test_pred_class <- predict(rf_fit, new_data = rf_test)\n",
    "rf_test_pred_prob <- predict(rf_fit, new_data = rf_test, type = 'prob') %>% dplyr::select(.pred_1)\n",
    "rf_test_pred_all <- cbind(rf_test_pred_class, rf_test_pred_prob, rf_test[['climate_change_worry']]) \n",
    "names(rf_test_pred_all) <- c('pred_class', 'pred_prob', 'truth')\n",
    "\n",
    "# Assess model performance on test set \n",
    "(rf_auc <- roc(rf_test_pred_all[['truth']], rf_test_pred_all[['pred_prob']]) %>% pROC::auc())\n",
    "(rf_logloss <- logLoss(as.numeric(rf_test_pred_all[['truth']]), rf_test_pred_all[['pred_prob']]))\n",
    "\n",
    "# Add results to list \n",
    "aucs[['randforest']] <- rf_auc\n",
    "log_losses[['randforest']] <- rf_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16aef475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.799771744839009"
      ],
      "text/latex": [
       "0.799771744839009"
      ],
      "text/markdown": [
       "0.799771744839009"
      ],
      "text/plain": [
       "Area under the curve: 0.7998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.389890543188193"
      ],
      "text/latex": [
       "-0.389890543188193"
      ],
      "text/markdown": [
       "-0.389890543188193"
      ],
      "text/plain": [
       "[1] -0.3898905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.3. Elastic net\n",
    "\n",
    "load('temp/tuning/enet_tuning.rda')\n",
    "\n",
    "enet_model <- logistic_reg(\n",
    "  penalty = enet_tune_best[['penalty']], \n",
    "  mixture = enet_tune_best[['mixture']]) %>% \n",
    "  set_mode('classification') %>% \n",
    "  set_engine('glmnet')\n",
    "\n",
    "dv <- 'climate_change_worry' \n",
    "enet_formula <- as.formula(paste0(dv, ' ~ .'))\n",
    "\n",
    "enet_fit <- enet_model %>% \n",
    "  fit(enet_formula, data = enet_train)\n",
    "\n",
    "# Create test assessment object \n",
    "enet_test_pred_class <- predict(enet_fit, new_data = enet_test)\n",
    "enet_test_pred_prob <- predict(enet_fit, new_data = enet_test, type = 'prob') %>% dplyr::select(.pred_1)\n",
    "enet_test_pred_all <- cbind(enet_test_pred_class, enet_test_pred_prob, enet_test[['climate_change_worry']]) \n",
    "names(enet_test_pred_all) <- c('pred_class', 'pred_prob', 'truth')\n",
    "\n",
    "# Assess model performance on test set \n",
    "(enet_auc <- roc(enet_test_pred_all[['truth']], enet_test_pred_all[['pred_prob']]) %>% pROC::auc())\n",
    "(enet_logloss <- logLoss(as.numeric(enet_test_pred_all[['truth']]), enet_test_pred_all[['pred_prob']]))\n",
    "\n",
    "# Add results to list \n",
    "aucs[['elasticnet']] <- enet_auc\n",
    "log_losses[['elasticnet']] <- enet_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3dd05c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.510696234350943"
      ],
      "text/latex": [
       "0.510696234350943"
      ],
      "text/markdown": [
       "0.510696234350943"
      ],
      "text/plain": [
       "Area under the curve: 0.5107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.0622062661055199"
      ],
      "text/latex": [
       "-0.0622062661055199"
      ],
      "text/markdown": [
       "-0.0622062661055199"
      ],
      "text/plain": [
       "[1] -0.06220627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.4. PCA \n",
    "\n",
    "load('temp/tuning/pca_tuning.rda')\n",
    "\n",
    "# Define mixed model formula\n",
    "dv <- 'climate_change_worry'\n",
    "best_components <- c('PC1', 'PC2', 'PC3', 'PC4')\n",
    "model_formula <- as.formula(paste0(dv, ' ~ (1|state_fips) + ', paste(best_components, collapse = '+')))\n",
    "\n",
    "# Fit model\n",
    "pca_fit <- glmer(model_formula, data = pca_train, family = binomial(link = 'logit'))\n",
    "\n",
    "# Create test assessment object \n",
    "pca_test_pred_prob <- predict(pca_fit, pca_test, type = 'response') %>% as.numeric()\n",
    "pca_test_pred_class <- ifelse(pca_test_pred_prob > 0.5, 1, 0) %>% as.factor()\n",
    "pca_test_pred_all <- data.frame(pca_test_pred_class, pca_test_pred_prob, pca_test[['climate_change_worry']]) \n",
    "names(pca_test_pred_all) <- c('pred_class', 'pred_prob', 'truth')\n",
    "\n",
    "# Assess model performance on test set \n",
    "(pca_auc <- roc(pca_test_pred_all[['truth']], pca_test_pred_all[['pred_prob']]) %>% pROC::auc())\n",
    "(pca_logloss <- logLoss(as.numeric(pca_test_pred_all[['truth']]), pca_test_pred_all[['pred_prob']]))\n",
    "\n",
    "# Add results to list \n",
    "aucs[['PCA']] <- pca_auc\n",
    "log_losses[['PCA']] <- pca_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2e6d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.562652899536308"
      ],
      "text/latex": [
       "0.562652899536308"
      ],
      "text/markdown": [
       "0.562652899536308"
      ],
      "text/plain": [
       "Area under the curve: 0.5627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.0676000785749417"
      ],
      "text/latex": [
       "-0.0676000785749417"
      ],
      "text/markdown": [
       "-0.0676000785749417"
      ],
      "text/plain": [
       "[1] -0.06760008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.5. Best subsets \n",
    "\n",
    "load('temp/tuning/bestsub_tuning.rda')\n",
    "\n",
    "# Define mixed model formula\n",
    "dv <- 'climate_change_worry'\n",
    "model_formula <- as.formula(paste0(dv, ' ~ (1|state_fips) + ', paste(best_features, collapse = '+')))\n",
    "\n",
    "# Fit model \n",
    "bestsub_fit <- glmer(model_formula, data = bestsub_train, family = binomial(link = 'logit'))\n",
    "\n",
    "# Create test assessment object \n",
    "bestsub_test_pred_prob <- predict(bestsub_fit, bestsub_test, type = 'response') %>% as.numeric()\n",
    "bestsub_test_pred_class <- ifelse(bestsub_test_pred_prob > 0.5, 1, 0) %>% as.factor()\n",
    "bestsub_test_pred_all <- data.frame(bestsub_test_pred_class, bestsub_test_pred_prob, bestsub_test[['climate_change_worry']]) \n",
    "names(bestsub_test_pred_all) <- c('pred_class', 'pred_prob', 'truth')\n",
    "\n",
    "# Assess model performance on test set \n",
    "(bestsub_auc <- roc(bestsub_test_pred_all[['truth']], bestsub_test_pred_all[['pred_prob']]) %>% pROC::auc())\n",
    "(bestsub_logloss <- logLoss(as.numeric(bestsub_test_pred_all[['truth']]), bestsub_test_pred_all[['pred_prob']]))\n",
    "\n",
    "# Add results to list \n",
    "aucs[['bestsub']] <- bestsub_auc\n",
    "log_losses[['bestsub']] <- bestsub_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cf9d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.807891972690179"
      ],
      "text/latex": [
       "0.807891972690179"
      ],
      "text/markdown": [
       "0.807891972690179"
      ],
      "text/plain": [
       "Area under the curve: 0.8079"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.224600352265559"
      ],
      "text/latex": [
       "-0.224600352265559"
      ],
      "text/markdown": [
       "-0.224600352265559"
      ],
      "text/plain": [
       "[1] -0.2246004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Ensemble\n",
    "\n",
    "# 4.1. Averaging all predictions \n",
    "avg_test_pred_prob <- (xgb_test_pred_all[['pred_prob']] + \n",
    "                       rf_test_pred_all[['pred_prob']] +\n",
    "                       enet_test_pred_all[['pred_prob']] + \n",
    "                       pca_test_pred_all[['pred_prob']] + \n",
    "                       bestsub_test_pred_all[['pred_prob']]) / 5\n",
    "\n",
    "avg_test_pred_class <- ifelse(avg_test_pred_prob > 0.5, 1, 0) %>% as.factor()\n",
    "\n",
    "avg_test_pred_all <- data.frame(avg_test_pred_class, \n",
    "                                avg_test_pred_prob, \n",
    "                                bestsub_test[['climate_change_worry']]) \n",
    "\n",
    "names(avg_test_pred_all) <- c('pred_class', 'pred_prob', 'truth')\n",
    "\n",
    "# Assess model performance \n",
    "(avg_auc <- roc(avg_test_pred_all[['truth']], avg_test_pred_all[['pred_prob']]) %>% pROC::auc())\n",
    "(avg_logloss <- logLoss(as.numeric(avg_test_pred_all[['truth']]), avg_test_pred_all[['pred_prob']]))\n",
    "\n",
    "# Add results to list -- AUC is slightly worse than just XGBoost model \n",
    "aucs[['ensemble_avg']] <- avg_auc\n",
    "log_losses[['ensemble_avg']] <- avg_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff5ff6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.809874897318844"
      ],
      "text/latex": [
       "0.809874897318844"
      ],
      "text/markdown": [
       "0.809874897318844"
      ],
      "text/plain": [
       "Area under the curve: 0.8099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.276094640679885"
      ],
      "text/latex": [
       "-0.276094640679885"
      ],
      "text/markdown": [
       "-0.276094640679885"
      ],
      "text/plain": [
       "[1] -0.2760946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.2. Weighted averaging all predictions \n",
    "auc_scores_vec  <- c(aucs[['xgboost']], aucs[['randforest']], aucs[['elasticnet']], aucs[['PCA']], aucs[['bestsub']])\n",
    "ranked_indices <- order(auc_scores_vec, decreasing = TRUE)\n",
    "weights <- 1 / (ranked_indices + 1)\n",
    "weights <- weights / sum(weights)\n",
    "\n",
    "# Apply weights \n",
    "avg_test_pred_prob_weighted <- (xgb_test_pred_all[['pred_prob']] * weights[1] + \n",
    "                                rf_test_pred_all[['pred_prob']] * weights[2] + \n",
    "                                enet_test_pred_all[['pred_prob']] * weights[3] + \n",
    "                                pca_test_pred_all[['pred_prob']] * weights[4] + \n",
    "                                bestsub_test_pred_all[['pred_prob']] * weights[5])\n",
    "\n",
    "avg_test_pred_class_weighted <- ifelse(avg_test_pred_prob_weighted > 0.5, 1, 0) %>% as.factor()\n",
    "\n",
    "avg_test_pred_weighted <- data.frame(avg_test_pred_class_weighted, \n",
    "                                     avg_test_pred_prob_weighted, \n",
    "                                     bestsub_test[['climate_change_worry']]) \n",
    "\n",
    "names(avg_test_pred_weighted) <- c('pred_class', 'pred_prob', 'truth')\n",
    "\n",
    "# Assess avg model performance \n",
    "(avg_auc_weighted <- roc(avg_test_pred_weighted[['truth']], avg_test_pred_weighted[['pred_prob']]) %>% pROC::auc())\n",
    "(avg_logloss <- logLoss(as.numeric(avg_test_pred_weighted[['truth']]), avg_test_pred_weighted[['pred_prob']]))\n",
    "\n",
    "# Add results to list -- AUC is better than all other models \n",
    "aucs[['ensemble_wgtavg']] <- avg_auc_weighted\n",
    "log_losses[['ensemble_wgtavg']] <- avg_logloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26447f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.809807565412947"
      ],
      "text/latex": [
       "0.809807565412947"
      ],
      "text/markdown": [
       "0.809807565412947"
      ],
      "text/plain": [
       "Area under the curve: 0.8098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.393128243758448"
      ],
      "text/latex": [
       "-0.393128243758448"
      ],
      "text/markdown": [
       "-0.393128243758448"
      ],
      "text/plain": [
       "[1] -0.3931282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.3. Weighted averaging predictions from best performing models -- AUC\n",
    "auc_scores_vec  <- c(aucs[['xgboost']], aucs[['randforest']], aucs[['elasticnet']])\n",
    "ranked_indices <- order(auc_scores_vec, decreasing = TRUE)\n",
    "\n",
    "weights <- 1 / (ranked_indices + 1)\n",
    "weights <- weights / sum(weights)\n",
    "\n",
    "# Apply weights \n",
    "avg_test_pred_prob_weighted_top3 <- (xgb_test_pred_all[['pred_prob']] * weights[1] + \n",
    "                                     rf_test_pred_all[['pred_prob']] * weights[2] + \n",
    "                                     enet_test_pred_all[['pred_prob']] * weights[3])\n",
    "\n",
    "avg_test_pred_class_weighted_top3 <- ifelse(avg_test_pred_prob_weighted_top3 > 0.5, 1, 0) %>% as.factor()\n",
    "\n",
    "avg_test_pred_weighted_top3 <- data.frame(avg_test_pred_class_weighted_top3, \n",
    "                                          avg_test_pred_prob_weighted_top3, \n",
    "                                          bestsub_test[['climate_change_worry']]) \n",
    "\n",
    "names(avg_test_pred_weighted_top3) <- c('pred_class', 'pred_prob', 'truth')\n",
    "\n",
    "# Assess avg model performance \n",
    "(avg_auc_weighted_top3 <- roc(avg_test_pred_weighted_top3[['truth']],  avg_test_pred_weighted_top3[['pred_prob']]) %>% pROC::auc())\n",
    "(avg_logloss_weighted_top3 <- logLoss(as.numeric(avg_test_pred_weighted_top3[['truth']]), avg_test_pred_weighted_top3[['pred_prob']]))\n",
    "\n",
    "\n",
    "# Add results to list -- AUC is the same \n",
    "aucs[['ensemble_wgtavg_3']] <- avg_auc_weighted_top3\n",
    "log_losses[['ensemble_wgtavg_3']] <- avg_logloss_weighted_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c66874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Save AUCs to evaluate later\n",
    "outpath <- \"output/3_aucs\"\n",
    "create_directory(outpath)\n",
    "save(aucs, file=file.path(outpath, \"auc_assessment.rda\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
